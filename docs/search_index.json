[["index.html", "Metodologías bayesianas para la estimación de la Escala de Experiencia de Inseguridad Alimentaria Introducción", " Metodologías bayesianas para la estimación de la Escala de Experiencia de Inseguridad Alimentaria Andrés Gutiérrez1, Stalyn Guerrero2 2023-09-22 Introducción Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["modelo-de-área-para-la-estimación-de-la-escala-de-experiencia-de-inseguridad-alimentaria.html", "Capítulo 1 Modelo de área para la estimación de la Escala de Experiencia de Inseguridad Alimentaria", " Capítulo 1 Modelo de área para la estimación de la Escala de Experiencia de Inseguridad Alimentaria El índice FIES (Escala de Experiencia de Inseguridad Alimentaria) se define como un sistema de medición para la inseguridad alimentaria a nivel individual y del hogar. La FIES se basa en cuestionarios que preguntan sobre las experiencias de los individuos y hogares en relación con el acceso a alimentos seguros y nutritivos. Estos cuestionarios se utilizan para definir un modelo probabilístico que vincule la medida (desconocida) de la inseguridad alimentaria con las respuestas (observables) a los cuestionarios basados en la experiencia. El modelo más sencillo utilizado para esto es el modelo de Rasch. Los indicadores definidos son los porcentajes de individuos de la población con edades a partir de 15 años que experimentan niveles de inseguridad alimentaria moderada o grave (IA moderada+grave) y grave (IA grave). Estos indicadores se calculan utilizando una escala numérica que va desde 0 hasta 40, donde 0 indica seguridad alimentaria total y 40 indica inseguridad alimentaria extrema. Los puntajes más altos en la escala indican una mayor gravedad de la inseguridad alimentaria. "],["modelo-de-rash.html", "1.1 Modelo de Rash", " 1.1 Modelo de Rash El modelo de Rasch es un modelo matemático utilizado para el análisis de datos en la medición de habilidades y características de los individuos. Este modelo es ampliamente utilizado en la educación, psicología, medicina y otras áreas de investigación. El modelo de Rasch se basa en la teoría de respuesta al ítem, que establece que la probabilidad de que un individuo responda correctamente a un ítem en particular depende de la habilidad del individuo y de la dificultad del ítem. El modelo de Rasch supone que la habilidad de un individuo y la dificultad de un ítem se pueden medir en una misma escala de medida, y que esta escala es unidimensional y lineal. La ecuación del modelo de Rasch es la siguiente: \\[ P_i(X_j=1) = \\frac{\\exp(a_i -b_j)}{1 + \\exp(a_i -b_j)} \\] donde \\(P_i(X_j=1)\\) es la probabilidad de que el individuo \\(i\\) responda correctamente al ítem \\(j\\), \\(a_i\\) es el nivel de habilidad del individuo \\(i\\), \\(b_j\\) es la dificultad del ítem \\(j\\), y \\(X_j\\) es una variable indicadora que toma el valor de 1 si el individuo \\(i\\) responde correctamente al ítem \\(j\\), y 0 en caso contrario. El proceso de estimación de los parámetros del modelo de Rasch se lleva a cabo mediante un procedimiento de máxima verosimilitud. Este proceso permite estimar tanto los niveles de habilidad de los individuos como las dificultades de los ítems. En el caso de las encuestas complejas, se utilizan métodos de estimación de la verosimilitud basados en muestras complejas para ajustar los parámetros del modelo. Es importante tener en cuenta el diseño de muestreo y la ponderación de las observaciones al utilizar el modelo de Rasch en encuestas complejas. "],["fuentes-de-error-en-la-estimación-del-fies.html", "1.2 Fuentes de error en la estimación del FIES", " 1.2 Fuentes de error en la estimación del FIES Error de muestreo: Este error se produce debido a la variabilidad natural en los datos recopilados a partir de una muestra de la población. Cuanto mayor sea el tamaño de la muestra, menor será este error. Error de medición: Este error se produce debido a la variabilidad en las respuestas proporcionadas por los encuestados. El modelo de Rasch utilizado para estimar la inseguridad alimentaria tiene en cuenta este error y proporciona estimaciones precisas. Debido a que los errores de muestreo y medición se consideran independientes, estos se combinan para obtener el error estándar de la prevalencia mundial de la siguiente forma: \\[ \\sigma^{2}_{total} = (Error de Muestreo)^2 + (Error de Medición)^2 \\] "],["modelos-de-área.html", "1.3 Modelos de área", " 1.3 Modelos de área La estimación de áreas pequeñas es un conjunto de técnicas que permiten la estimación de parámetros de interés para dominios donde los estimadores directos no pueden considerarse lo suficientemente confiables debido a que su varianza es demasiado alta para ser liberada. Las encuestas de oficinas estadísticas nacionales suelen planificarse a un nivel más alto, por lo que cuando se requiere información más detallada, el tamaño de la muestra puede no ser lo suficientemente grande como para garantizar la liberación de estimaciones directas y, en algunos casos, es posible que los dominios más pequeños no cuenten con unidades de muestra. Los métodos de estimación de áreas pequeñas aumentan la confiabilidad de la estimación “tomando fuerza prestada” de un conjunto de áreas en un dominio más grande para el cual el estimador directo es confiable. Esto significa que se utiliza información de otras áreas y / o se explota información adicional de diferentes fuentes. Uno de los modelos más utilizados para la estimación de áreas pequeñas es el modelo de Fay-Herriot. El modelo de Fay-Herriot es un modelo lineal mixto que se utiliza para estimar parámetros de interés para pequeñas áreas en presencia de datos auxiliares. El modelo se utiliza para “prestar fuerza” de áreas más grandes a áreas más pequeñas y, por lo tanto, aumentar la precisión de las estimaciones para áreas pequeñas. En el modelo de Fay-Herriot, el parámetro de interés en cada área pequeña se modela como una combinación lineal de un estimador directo de la encuesta y un componente predicho basado en un modelo lineal mixto. El modelo relaciona el parámetro de interés con las variables auxiliares conocidas para cada uno de los dominios que constituyen la partición de la población completa. Se incluye un efecto para tener en cuenta la homogeneidad dentro de cada dominio. 1.3.1 Modelo de área de Fay-Herriot Sea \\(P_d\\) la probabilidad de encontrar un hogar con inseguridad alimentaria en el \\(d-\\)ésimo dominio de la población. Entonces, el estimador directo de \\(P_d\\) se puede escribir como: \\[ \\hat{P}^{DIR}_{d} = P_d + e_d \\] Ahora bien, \\(P_d\\) se puede modelar de la siguiente manera, \\[ P_d = \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d \\] Luego, reescribiendo \\(\\hat{P}^{DIR}_{d}\\) en términos de las dos ecuaciones anteriores tenemos: \\[ \\hat{P}^{DIR}_{d} = \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d + e_d \\] Ahora, es posible suponer que \\(\\hat{P}^{DIR}_d \\sim N(\\boldsymbol{x}^{T}_{d}\\boldsymbol \\beta, \\sigma_u^2 +\\sigma_{e_d}^2)\\), \\(\\hat{P}^{DIR}_d \\mid u_d \\sim N(\\boldsymbol{x}^{T}_{d}\\boldsymbol \\beta + u_d,\\sigma_{e_d}^2)\\) y \\(u_d \\sim N(0, \\sigma^2_u)\\) Luego, se asumen distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_u\\) \\[ \\begin{eqnarray*} \\beta_p &amp; \\sim &amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim &amp; IG(0.0001, 0.0001) \\end{eqnarray*} \\] por tanto, el estimador bayesiano para \\(P_d\\) esta dado como \\(\\tilde{P}_d = E\\left(P_d\\mid\\hat{P}_d^{DIR}\\right)\\) 1.3.2 Modelo de área de Fay-Herriot con tranformación arcoseno. En su concepción más básica, el modelo de Fay-Herriot es una combinación lineal de covariables. Sin embargo, el resultado de esta combinación pueden tomar valores que se salen del rango aceptable en el que puede estar una proporción; es decir, en general el estimador de Fay-Herriot \\(\\theta \\in R\\), mientras que el estimador directo \\(\\theta \\in (0,1)\\). La transformación arcoseno esta dada por: \\[ \\hat{z}_d = arcsin\\left( \\sqrt{ \\hat{\\theta}_d} \\right) \\] donde \\[ Var\\left( \\hat{z}_d \\right) = \\frac{\\widehat{DEFF}_d}{4\\times n_d} = \\frac{1}{4\\times n_{d,efectivo} } \\] El modelo de Fay-Herriot estaría definido de la siguiente forma: \\[ \\begin{eqnarray*} Z_d \\mid \\mu_d,\\sigma^2_d &amp; \\sim &amp; N(\\mu_d, \\sigma^2_d)\\\\ \\mu_d &amp; = &amp; \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d \\\\ \\theta_d &amp; = &amp; \\left(sin(\\mu_d)\\right)^2 \\end{eqnarray*} \\] donde \\(u_d \\sim N(0 , \\sigma^2)\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,1000 \\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] 1.3.3 Modelos de área con variable respuesta Beta. El modelo beta-logístico fue inicialmente considerado por Jiang y Lahiri (2006b) para un enfoque EBP en uno de sus ejemplos ilustrativos para estimar medias de dominio de población finita. El modelo de área beta-logístico estaría dado por las siguientes expresiones \\[ \\begin{eqnarray*} \\hat{p}_{d} \\mid P_d &amp; \\sim &amp; beta(a_d, b_d)\\\\ \\end{eqnarray*} \\] La función del enlace es \\[ \\begin{eqnarray*} logit(P_{d}) \\mid \\boldsymbol{\\beta}, \\sigma^2_u &amp; \\sim &amp; N(\\boldsymbol{x}_d^T\\boldsymbol{\\beta},\\sigma^2_u)\\\\ \\end{eqnarray*} \\] Los parámetros \\(a_d\\) y \\(b_d\\) son estimados así: \\[ \\begin{eqnarray*} a_d &amp;=&amp; P_d \\times \\phi_d\\\\ b_d &amp;=&amp; (1 - P_d) \\times \\phi_d\\\\ \\end{eqnarray*} \\] donde \\[\\phi_d = \\frac{n_d}{\\widehat{DEFF}_d} -1 = n_{d,efecctivo} -1\\] Las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_u\\) \\[ \\begin{eqnarray*} \\beta_k &amp;\\sim&amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim&amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] 1.3.4 Modelos de área con variable respuesta Binomial. El modelo lineal de Fay-Herriot puede ser reemplazado por un modelo mixto lineal generalizado (GLMM). Esto se puede hacer cuando los datos observados \\(Y_d\\) son inherentemente discretos, como cuando son recuentos (no ponderados) de personas u hogares muestreados con ciertas características. Uno de estos modelos supone una distribución binomial para \\(Y_d\\) con probabilidad de éxito \\(\\theta_d\\), y una logística modelo de regresión para \\(\\theta_d\\) con errores normales en la escala logit. El modelo resultante es \\[ \\begin{eqnarray*} Y_{d}\\mid \\theta_{d},n_{d} &amp; \\sim &amp; Bin\\left(n_{d},\\theta_{d}\\right) \\end{eqnarray*} \\] para \\(d=1,\\dots,D\\) y \\[ \\begin{eqnarray*} logit\\left(\\theta_{d}\\right)=\\log\\left(\\frac{\\theta_{d}}{1-\\theta_{d}}\\right) &amp; = &amp; \\boldsymbol{x}_{d}^{T}\\boldsymbol{\\beta}+u_{d} \\end{eqnarray*} \\] donde \\(u_{d}\\sim N\\left(0,\\sigma_{u}^{2}\\right)\\) y \\(n_{d}\\) es el tamaño de la muestra para el área \\(d\\). El modelo anterior se puede aplicar fácilmente a recuentos de muestras no ponderadas \\(Y_d\\), pero esto ignora cualquier aspecto complejo del diseño de la encuesta. En muestras complejas donde las \\(Y_d\\) son estimaciones ponderadas, surgen dos problemas. En primer lugar, los posibles valores de el \\(Y_d\\) no serán los números enteros \\(0, 1, \\dots , n_d\\) para cualquier definición directa de tamaño de muestra \\(n_d\\). En su lugar, \\(Y_d\\) tomará un valor de un conjunto finito de números desigualmente espaciados determinados por las ponderaciones de la encuesta que se aplican a los casos de muestra en el dominio \\(d\\). En segundo lugar, la varianza muestral de \\(Y_d\\) implícito en la distribución Binomial, es decir, \\(n_d \\times \\theta_d (1-\\theta_d)\\), será incorrecto. Abordamos estos dos problemas al definir un tamaño de muestra efectivo \\(\\tilde{n}_d\\), y un número de muestra efectivo de éxitos \\(\\tilde{Y_d}\\) determinó mantener: (i) la estimación directa \\(\\hat{\\theta}_i\\), de la pobreza y (ii) una estimación de la varianza de muestreo correspondiente,\\(\\widehat{Var}(\\hat{\\theta}_d)\\). Es posible suponer que \\[ \\begin{eqnarray*} \\tilde{n}_{d} &amp; \\sim &amp; \\frac{\\check{\\theta}_{d}\\left(1-\\check{\\theta}_{d}\\right)}{\\widehat{Var}\\left(\\hat{\\theta}_{d}\\right)} \\end{eqnarray*} \\] donde \\(\\check{\\theta}_{d}\\) es una preliminar perdicción basada en el modelo para la proporción poblacional \\(\\theta_d\\) y \\(\\widehat{Var}\\left(\\hat{\\theta}_{d}\\right)\\) depende de\\(\\check{\\theta}_{d}\\) a través de una función de varianza generalizada ajustada (FGV). Note que \\(\\tilde{Y}_{d}=\\tilde{n}_{d}\\times\\hat{\\theta}_{d}\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,10000\\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] "],["estimación-de-la-escala-de-experiencia-de-inseguridad-alimentaria.html", "Capítulo 2 Estimación de la Escala de Experiencia de Inseguridad Alimentaria", " Capítulo 2 Estimación de la Escala de Experiencia de Inseguridad Alimentaria Luego de recopilar la información proporcionada por FAO, se procedió al ajuste de los 4 modelos anteriores utilizando un conjunto de covariables detalladas a continuación: region accesibilidad_hospitales luces_nocturnas prop_b50median_afc_2020 prop_fonasa_a_2019 prop_fonasa_c_2019 tasa_victimizacion_2019 tasa_mort_infantil_2017 log_ing_municipales_permanentes_pc_2018 prop_am_bajo_peso_2018 prop_am_normal_2018 prop_am_obeso_2018 prop_obeso_sobrepeso_menores_2018 prop_riesgo_desnutricion_menores_2018 prop_obeso_sobrepeso_menores_2018_w prop_isapre_2019 prop_red_publica_2017 prop_camion_aljibe_2017 prop_rio_vertiente_estero_canal_2017 prop_deficit_habitacional_cuantitativo_2017 indice_de_vejez_2020 Posteriormente, se llevó a cabo un análisis de chequeo predictivo con el fin de seleccionar el modelo más adecuado. Cabe destacar que se realizaron 6500 iteraciones, descartando las primeras 5000 iteraciones como parte del proceso de quemado. Al evaluar el criterio de Rhat, se pudo constatar que todas las cadenas del modelo convergieron satisfactoriamente. Resultado para el modelo de área de Fay-Herriot. Resultado para el Modelo de área de Fay-Herriot con tranformación arcoseno. Resultado para el modelo de área con variable respuesta Beta. Resultado para el modelo de área con variable respuesta Binomial. De acuerdo con los resultados obtenidos, se determinó que el modelo de área con variable respuesta beta presenta un mejor ajuste en comparación con los otros modelos considerados. A partir de este modelo, se procedió a realizar el proceso de benchmarking, el cual se describe a continuación: "],["proceso-de-estimación-y-benchmark.html", "2.1 Proceso de estimación y Benchmark", " 2.1 Proceso de estimación y Benchmark Leer el modelo y el archivo que contiene el orden en que ingresaron las comunas al modelo. model_FH_beta_logitic &lt;- readRDS(&quot;Data/model_FH_beta_logitic.rds&quot;) estimacionesPre &lt;- readRDS(&quot;Data/id_Orden.rds&quot;) %&gt;% transmute(dam2 = str_pad(width = 5, comuna, pad = &quot;0&quot;), dam = str_sub(dam2, 1, 2), id_Orden) Obtener los valores posteriores tanto para las comunas observadas como para las no observadas. Organizar estos valores de manera que las filas representen cada comuna y las columnas correspondan a los valores posteriores. y_pred &lt;- as.array(model_FH_beta_logitic, pars = c(&quot;theta&quot;, &quot;thetapred&quot;)) %&gt;% as_draws_df() %&gt;% select(matches(&quot;theta&quot;)) y_pred &lt;- data.frame(t(y_pred)) %&gt;% as_tibble() colnames(y_pred) &lt;- paste0(&quot;iter_&quot;, 1:ncol(y_pred)) y_pred %&lt;&gt;% mutate(id_Orden = 1:n()) Asignar los valores posteriores a la comuna correspondiente. estimacionesPre &lt;- inner_join(estimacionesPre, y_pred) Del censo extraer el total de personas por Región total_hh &lt;- readRDS(file = &quot;Data/Total_Hogares.rds&quot;) N_hh &lt;- total_hh %&gt;% group_by(dam = str_sub(dam2, 1, 2)) %&gt;% mutate(dam_hh = sum(NN_Hogar)) tba(N_hh %&gt;% data.frame() %&gt;% slice(1:10)) dam2 NN_Hogar dam dam_hh 01101 60226 01 97693 01107 29699 01 97693 01401 4188 01 97693 01402 484 01 97693 01403 488 01 97693 01404 965 01 97693 01405 1643 01 97693 02101 105863 02 174314 02102 3430 02 174314 02103 358 02 174314 Obtener las estimaciones directa por región o el nivel de agregación en el cual la encuesta es representativa. directoDam &lt;- readRDS(&quot;Data/FIES_region.rds&quot;) %&gt;% dplyr::select( dam, ModerateSevere = FIES) Realizar el consolidando información obtenida hasta el momento. temp &lt;- estimacionesPre %&gt;% inner_join(N_hh ) %&gt;% inner_join(directoDam ) Con la información organizada realizar de los ponderadores para cada uno de los valores posteriores R_dam2 &lt;- temp %&gt;% group_by(dam) %&gt;% mutate(across( starts_with(&quot;iter_&quot;), ~ unique(ModerateSevere) / sum((NN_Hogar / dam_hh) * .), .names = &quot;gk_{.col}&quot; ), across(starts_with(&quot;iter_&quot;), ~NULL) ) tba(R_dam2[1:10,c(1,2,7:12)]) calculando los pesos para cada comuna pesos &lt;- temp %&gt;% mutate(W_i = NN_Hogar / dam_hh) %&gt;% select(dam2, W_i) Multiplicar cada ponderador (\\(gk_i\\)) por la respectiva realización posterior (\\(iter_i\\)). Esto generará una estimación de benchmarking para cada uno de los valores posteriores. names_iter &lt;- grep(pattern = &quot;iter_&quot;,names(temp),value = TRUE) llave &lt;- intersect(names(estimacionesPre),names(R_dam2)) paso &lt;- estimacionesPre %&gt;% left_join(R_dam2 , by = llave) for(x in names_iter){ cat(x,&quot;\\n&quot;) columna_prefijo &lt;- sym(paste0(&quot;gk_&quot;, x)) columna_resultado &lt;- sym(paste0(&quot;RBench_&quot;, x)) paso %&lt;&gt;% mutate(!!columna_resultado := !!sym(x) * !!columna_prefijo) } saveRDS(paso, file = &quot;Data/replicas_RBench.rds&quot;) Los resultados obtenidos se muestra en la siguiente tabla. paso &lt;- readRDS(&quot;Data/replicas_RBench.rds&quot;) paso_RBench &lt;- paso %&gt;% select(matches(&quot;RBench_&quot;)) tba(paso_RBench[1:10,c(1:5)]) RBench_iter_1 RBench_iter_2 RBench_iter_3 RBench_iter_4 RBench_iter_5 0.1764 0.1794 0.1795 0.1809 0.1807 0.2996 0.2915 0.2909 0.2931 0.2941 0.2137 0.2333 0.2343 0.2130 0.2137 0.2093 0.1996 0.2007 0.1818 0.1758 0.1939 0.1959 0.1959 0.1942 0.1979 0.2522 0.2686 0.2745 0.2710 0.2836 0.2200 0.2613 0.2626 0.2394 0.2444 0.1937 0.1867 0.1872 0.1943 0.1878 0.2287 0.2235 0.2277 0.2229 0.2278 0.2246 0.2174 0.2088 0.2056 0.1868 En proceso de estimación se hace calculando el promedio y desviación estándar para cada comuna a partir de l resultado anterior. estimacionesBench &lt;- data.frame( dam = paso$dam, dam2 = paso$dam2, theta_pred_RBench_rep = apply(paso_RBench,MARGIN = 1,mean), theta_pred_RBench_rep_sd = apply(paso_RBench,MARGIN = 1,sd) ) %&gt;% left_join(pesos) tba(estimacionesBench %&gt;% slice(1:10)) dam dam2 theta_pred_RBench_rep theta_pred_RBench_rep_sd W_i 01 01101 0.1862 0.0062 0.6165 01 01107 0.2786 0.0123 0.3040 01 01401 0.2247 0.0143 0.0429 01 01405 0.2085 0.0173 0.0168 02 02101 0.1934 0.0047 0.6073 02 02102 0.2327 0.0219 0.0197 02 02104 0.2300 0.0235 0.0208 02 02201 0.1942 0.0093 0.2781 02 02203 0.2536 0.0240 0.0172 02 02301 0.2192 0.0207 0.0459 Validación: Estimación FH con Benchmark estimacionesBench %&gt;% group_by(dam) %&gt;% summarise(theta_reg_RB = sum(W_i * theta_pred_RBench_rep)) %&gt;% left_join(directoDam, by = &quot;dam&quot;) %&gt;% data.frame() %&gt;% tba() "],["validación-de-los-resultados..html", "2.2 Validación de los resultados.", " 2.2 Validación de los resultados. La visualización resultante del siguiente código muestra puntos de diferentes formas y colores para representar los diferentes métodos de estimación, y dos líneas punteadas que representan los intervalos de confianza superior e inferior para los valores observados en la variable theta_dir. El siguiente código define los intervalos de confianza para las estimaciones directas. IC_dir &lt;- readRDS(&quot;Data/FIES_region.rds&quot;) %&gt;% dplyr::select(dam, FIES, var_hat) %&gt;% transmute(dam, Ls = FIES + 1.96 * sqrt(var_hat), Li = FIES - 1.96 * sqrt(var_hat)) Ahora, examinar las estimaciones del modelo de área sin incluir el benchmark. estimacionesPre &lt;- readRDS(&quot;Data/estimacionesPre.rds&quot;) %&gt;% transmute(dam2 = comuna, dam = str_sub(dam2,1,2), theta_pred = pred_beta_log, theta_pred_EE = pred_beta_log_EE) A continuación se consolida las base con las estimaciones por comuna. temp &lt;- estimacionesBench %&gt;% left_join( estimacionesPre ) %&gt;% group_by(dam) %&gt;% summarise( &quot;FIES Modelo&quot; = sum(W_i * theta_pred), &quot;FIES Modelo Bench&quot; = sum(W_i * theta_pred_RBench_rep) ) %&gt;% left_join(directoDam, by = &quot;dam&quot;) %&gt;% mutate(id = 1:n()) temp %&lt;&gt;% gather(key = &quot;Metodo&quot;,value = &quot;Estimacion&quot;, -id, -dam) temp &lt;- inner_join(temp,IC_dir) p_temp &lt;- ggplot(data = temp, aes(x = id, y = Estimacion, shape = Metodo)) + geom_point(aes(color = Metodo), size = 2) + geom_line(aes(y = Li), linetype = 2) + geom_line(aes(y = Ls), linetype = 2) + theme_bw(10) + scale_x_continuous(breaks = temp$id, labels = temp$dam) + labs(y = &quot;&quot;, x = &quot;&quot;) ggsave( plot = p_temp, filename = &quot;Data/RecursosBook/03/1_validacion_Bench.jpeg&quot;, width = 12, height = 7 ) "],["mapa-con-la-estimación-de-la-escala-de-experiencia-de-inseguridad-alimentaria.html", "2.3 Mapa con la estimación de la Escala de Experiencia de Inseguridad Alimentaria", " 2.3 Mapa con la estimación de la Escala de Experiencia de Inseguridad Alimentaria 2.3.1 Tabla con las estimaciones por comuna. Region Comuna FIES FIES_ee FIES_cv(%) 15 15202 0.2239 0.0698 31.155 15 15102 0.1315 0.0345 26.220 12 12303 0.1183 0.0286 24.145 12 12402 0.1002 0.0238 23.782 12 12103 0.1127 0.0266 23.643 12 12102 0.1825 0.0425 23.287 02 02202 0.2250 0.0514 22.835 01 01403 0.2505 0.0515 20.562 05 05504 0.1010 0.0192 18.973 12 12104 0.1089 0.0200 18.358 05 05104 0.1555 0.0278 17.897 12 12302 0.1690 0.0279 16.486 15 15201 0.2226 0.0343 15.404 05 05506 0.1550 0.0234 15.089 08 08314 0.3296 0.0489 14.839 12 12201 0.1892 0.0260 13.749 06 06309 0.1990 0.0273 13.716 05 05303 0.2021 0.0276 13.661 10 10103 0.2021 0.0276 13.649 12 12301 0.1742 0.0230 13.229 10 10401 0.1698 0.0213 12.531 06 06202 0.1499 0.0187 12.485 11 11302 0.2053 0.0256 12.460 01 01402 0.2506 0.0309 12.332 11 11102 0.1468 0.0176 11.989 02 02302 0.1493 0.0177 11.869 05 05605 0.1557 0.0180 11.593 10 10204 0.1878 0.0214 11.413 13 13115 0.0810 0.0089 10.953 09 09116 0.2443 0.0267 10.942 13 13132 0.0468 0.0051 10.814 05 05402 0.1706 0.0183 10.721 10 10404 0.1842 0.0197 10.716 10 10402 0.2318 0.0246 10.614 02 02103 0.2311 0.0242 10.491 11 11402 0.1977 0.0204 10.318 03 03302 0.2441 0.0251 10.296 16 16204 0.2191 0.0225 10.283 02 02104 0.2300 0.0235 10.224 09 09104 0.2876 0.0292 10.157 09 09121 0.2427 0.0244 10.067 11 11203 0.2219 0.0223 10.052 01 01404 0.2425 0.0244 10.048 04 04305 0.1757 0.0176 10.007 05 05404 0.1847 0.0184 9.939 09 09205 0.2739 0.0271 9.895 05 05201 0.2096 0.0207 9.883 04 04202 0.1791 0.0177 9.857 11 11303 0.2022 0.0199 9.850 04 04304 0.1949 0.0188 9.654 13 13502 0.1826 0.0176 9.631 13 13303 0.1631 0.0157 9.614 13 13505 0.2128 0.0204 9.589 04 04104 0.1951 0.0186 9.529 02 02203 0.2536 0.0240 9.465 02 02301 0.2192 0.0207 9.425 02 02102 0.2327 0.0219 9.398 06 06103 0.1718 0.0161 9.382 05 05606 0.1405 0.0131 9.347 07 07103 0.1783 0.0166 9.298 09 09204 0.3516 0.0323 9.178 10 10206 0.1810 0.0166 9.150 05 05703 0.1955 0.0177 9.061 13 13123 0.0638 0.0058 9.036 16 16202 0.1863 0.0167 8.976 08 08207 0.2858 0.0256 8.965 06 06205 0.1559 0.0140 8.952 07 07104 0.2565 0.0228 8.893 08 08310 0.2070 0.0183 8.832 08 08104 0.2195 0.0193 8.802 05 05405 0.1555 0.0137 8.794 05 05105 0.2023 0.0177 8.756 05 05403 0.1659 0.0144 8.688 13 13114 0.0592 0.0051 8.680 13 13203 0.1587 0.0138 8.668 09 09117 0.2988 0.0253 8.460 12 12401 0.1780 0.0150 8.446 03 03303 0.1751 0.0147 8.414 10 10209 0.1975 0.0164 8.307 10 10306 0.3012 0.0250 8.298 01 01405 0.2085 0.0173 8.297 06 06108 0.1290 0.0107 8.295 10 10210 0.2421 0.0200 8.272 08 08204 0.2164 0.0179 8.251 07 07107 0.1827 0.0150 8.220 03 03103 0.2321 0.0191 8.215 11 11401 0.1955 0.0158 8.108 13 13503 0.2028 0.0164 8.065 10 10207 0.2159 0.0172 7.987 08 08308 0.2389 0.0188 7.864 16 16304 0.2476 0.0194 7.846 05 05704 0.2080 0.0162 7.791 05 05602 0.1577 0.0123 7.786 09 09106 0.2708 0.0207 7.659 07 07203 0.1888 0.0144 7.652 09 09110 0.2278 0.0174 7.631 16 16206 0.1781 0.0135 7.589 07 07306 0.2098 0.0158 7.549 13 13504 0.1839 0.0139 7.544 16 16207 0.2049 0.0154 7.523 13 13301 0.1760 0.0132 7.497 05 05702 0.2199 0.0164 7.448 16 16205 0.2188 0.0163 7.446 08 08302 0.1995 0.0148 7.408 14 14102 0.2373 0.0175 7.385 03 03202 0.1673 0.0123 7.377 06 06206 0.2214 0.0163 7.377 06 06304 0.1898 0.0140 7.351 11 11202 0.2004 0.0147 7.346 06 06203 0.1890 0.0138 7.282 10 10403 0.2609 0.0190 7.274 11 11301 0.2018 0.0147 7.271 14 14203 0.2528 0.0183 7.231 13 13120 0.0828 0.0060 7.225 06 06306 0.1861 0.0134 7.174 07 07105 0.2113 0.0150 7.086 05 05107 0.2122 0.0150 7.064 10 10304 0.2529 0.0178 7.041 05 05705 0.2082 0.0146 7.012 07 07309 0.1698 0.0119 7.011 06 06308 0.2081 0.0145 6.992 04 04302 0.1987 0.0138 6.956 07 07202 0.2298 0.0159 6.914 07 07302 0.1757 0.0121 6.909 07 07303 0.1703 0.0118 6.909 13 13501 0.2194 0.0151 6.902 13 13113 0.0838 0.0058 6.889 06 06204 0.1816 0.0125 6.872 04 04105 0.2007 0.0138 6.862 05 05302 0.1917 0.0131 6.842 05 05304 0.1723 0.0118 6.835 07 07108 0.2114 0.0144 6.833 08 08109 0.1940 0.0132 6.813 03 03201 0.1944 0.0132 6.796 09 09118 0.2586 0.0176 6.795 09 09208 0.2607 0.0176 6.752 13 13202 0.1601 0.0108 6.739 06 06113 0.2008 0.0135 6.712 13 13302 0.2099 0.0141 6.701 10 10106 0.2720 0.0182 6.676 06 06307 0.2019 0.0134 6.640 08 08205 0.2114 0.0139 6.589 16 16203 0.1893 0.0125 6.580 10 10105 0.2290 0.0150 6.564 16 16104 0.2674 0.0175 6.552 13 13107 0.1632 0.0107 6.542 06 06104 0.2144 0.0140 6.527 05 05103 0.1310 0.0085 6.522 10 10302 0.2424 0.0156 6.441 09 09107 0.2262 0.0145 6.419 09 09207 0.2522 0.0161 6.394 10 10307 0.2176 0.0139 6.389 01 01401 0.2247 0.0143 6.383 07 07307 0.1952 0.0125 6.383 08 08201 0.2524 0.0161 6.366 06 06102 0.1968 0.0124 6.317 13 13404 0.2304 0.0145 6.312 10 10104 0.2422 0.0153 6.304 04 04203 0.2066 0.0130 6.300 06 06302 0.2211 0.0139 6.284 07 07106 0.1878 0.0118 6.268 09 09206 0.2373 0.0149 6.263 10 10208 0.2598 0.0162 6.238 10 10107 0.2122 0.0132 6.237 04 04204 0.1742 0.0108 6.215 06 06112 0.1763 0.0109 6.207 10 10108 0.2554 0.0158 6.201 10 10109 0.1747 0.0107 6.136 04 04106 0.2187 0.0134 6.125 06 06111 0.1869 0.0114 6.122 05 05803 0.2085 0.0128 6.116 03 03102 0.1848 0.0113 6.113 07 07110 0.1903 0.0116 6.100 04 04103 0.1630 0.0099 6.072 06 06305 0.2171 0.0131 6.051 16 16201 0.2107 0.0127 6.028 13 13403 0.1734 0.0104 5.981 13 13108 0.2316 0.0138 5.972 08 08312 0.2063 0.0123 5.968 10 10205 0.2368 0.0141 5.963 09 09105 0.2723 0.0162 5.945 13 13128 0.2346 0.0139 5.929 16 16107 0.2339 0.0139 5.921 07 07305 0.2093 0.0124 5.918 06 06105 0.1891 0.0112 5.910 13 13118 0.1525 0.0090 5.903 09 09115 0.2520 0.0148 5.887 08 08106 0.2199 0.0129 5.881 09 09210 0.2422 0.0142 5.859 06 06110 0.2069 0.0121 5.856 08 08309 0.2129 0.0124 5.834 13 13602 0.2127 0.0124 5.830 09 09209 0.2465 0.0143 5.787 04 04201 0.1844 0.0107 5.781 04 04303 0.2342 0.0135 5.776 10 10203 0.2150 0.0124 5.759 14 14108 0.2713 0.0156 5.758 07 07408 0.2362 0.0136 5.748 03 03304 0.1777 0.0102 5.745 07 07304 0.2072 0.0119 5.734 07 07102 0.2089 0.0120 5.728 05 05603 0.2184 0.0125 5.713 16 16108 0.2617 0.0149 5.688 09 09119 0.2698 0.0153 5.683 10 10305 0.2269 0.0129 5.682 05 05102 0.1862 0.0106 5.667 05 05503 0.2152 0.0122 5.655 08 08206 0.2393 0.0135 5.652 13 13603 0.2100 0.0119 5.652 06 06107 0.2254 0.0127 5.647 08 08108 0.1813 0.0102 5.643 08 08203 0.2631 0.0148 5.627 16 16303 0.2270 0.0128 5.623 16 16109 0.1863 0.0105 5.621 05 05604 0.2127 0.0119 5.616 10 10102 0.2411 0.0135 5.610 07 07405 0.2325 0.0130 5.604 06 06106 0.2049 0.0115 5.600 05 05801 0.1648 0.0092 5.598 08 08107 0.2248 0.0126 5.594 16 16305 0.2193 0.0123 5.588 16 16105 0.2364 0.0131 5.542 13 13125 0.2165 0.0118 5.469 13 13102 0.1971 0.0107 5.445 05 05502 0.2150 0.0117 5.428 13 13117 0.2516 0.0136 5.410 13 13402 0.1940 0.0105 5.410 09 09102 0.2624 0.0142 5.402 08 08313 0.2253 0.0122 5.394 13 13601 0.1959 0.0106 5.391 05 05706 0.2120 0.0114 5.384 05 05301 0.1785 0.0096 5.376 05 05802 0.1871 0.0101 5.376 08 08111 0.1913 0.0103 5.374 16 16106 0.2530 0.0136 5.370 07 07308 0.2374 0.0127 5.343 06 06114 0.2093 0.0111 5.297 08 08307 0.2317 0.0122 5.286 13 13605 0.1982 0.0105 5.275 13 13130 0.1235 0.0065 5.238 13 13103 0.2600 0.0136 5.235 13 13109 0.1681 0.0088 5.208 14 14103 0.2412 0.0125 5.175 14 14105 0.2372 0.0123 5.166 06 06201 0.2034 0.0105 5.158 08 08202 0.2036 0.0104 5.111 09 09103 0.2407 0.0123 5.099 08 08311 0.2377 0.0121 5.096 13 13106 0.2194 0.0112 5.093 16 16302 0.2815 0.0143 5.087 10 10303 0.2243 0.0114 5.080 09 09203 0.2351 0.0119 5.074 08 08105 0.2390 0.0120 5.033 08 08112 0.1998 0.0100 5.028 13 13131 0.2563 0.0129 5.022 08 08304 0.1994 0.0100 5.017 09 09202 0.2511 0.0126 5.010 06 06116 0.1993 0.0099 4.989 14 14104 0.2397 0.0119 4.979 05 05401 0.2064 0.0103 4.974 14 14204 0.2357 0.0117 4.974 05 05804 0.1867 0.0093 4.964 06 06109 0.2159 0.0107 4.960 07 07407 0.1974 0.0098 4.955 07 07402 0.2206 0.0109 4.942 08 08103 0.1832 0.0091 4.940 08 08110 0.1849 0.0091 4.940 09 09113 0.2476 0.0122 4.921 09 09114 0.2316 0.0114 4.902 05 05701 0.2219 0.0108 4.858 14 14201 0.2086 0.0101 4.829 13 13604 0.2038 0.0098 4.827 05 05601 0.2150 0.0103 4.799 02 02201 0.1942 0.0093 4.770 13 13116 0.2719 0.0129 4.757 08 08101 0.1740 0.0082 4.740 16 16103 0.2372 0.0112 4.723 06 06310 0.2086 0.0098 4.702 05 05109 0.1724 0.0081 4.679 06 06303 0.2292 0.0107 4.669 08 08306 0.2079 0.0097 4.657 13 13121 0.2317 0.0107 4.637 08 08305 0.2403 0.0111 4.634 16 16102 0.2412 0.0112 4.633 14 14202 0.2801 0.0130 4.624 13 13201 0.2139 0.0099 4.612 10 10202 0.2341 0.0107 4.590 07 07404 0.2155 0.0099 4.583 10 10301 0.2047 0.0093 4.562 08 08301 0.2225 0.0101 4.545 07 07109 0.2240 0.0102 4.544 08 08303 0.2283 0.0104 4.538 07 07201 0.1944 0.0088 4.525 09 09109 0.2448 0.0111 4.516 13 13129 0.2056 0.0093 4.504 06 06115 0.2378 0.0107 4.502 13 13104 0.2182 0.0098 4.501 13 13101 0.1832 0.0082 4.491 03 03301 0.1947 0.0087 4.474 10 10201 0.2115 0.0095 4.471 07 07403 0.2493 0.0111 4.465 09 09112 0.2807 0.0125 4.446 06 06301 0.1979 0.0088 4.439 14 14107 0.2381 0.0106 4.433 01 01107 0.2786 0.0123 4.432 13 13105 0.2600 0.0115 4.426 13 13124 0.2071 0.0091 4.411 13 13127 0.2371 0.0103 4.342 09 09111 0.2585 0.0112 4.326 13 13110 0.1709 0.0074 4.310 13 13111 0.2535 0.0109 4.304 13 13119 0.1680 0.0072 4.297 11 11201 0.2157 0.0092 4.275 13 13112 0.3151 0.0134 4.241 09 09201 0.2236 0.0095 4.235 09 09120 0.2500 0.0105 4.210 06 06117 0.1913 0.0080 4.171 13 13126 0.2094 0.0087 4.158 09 09108 0.2501 0.0103 4.129 08 08102 0.2270 0.0093 4.115 09 09211 0.2371 0.0097 4.087 13 13122 0.1949 0.0079 4.067 14 14106 0.2582 0.0105 4.060 05 05501 0.1957 0.0078 4.012 07 07301 0.2028 0.0080 3.968 16 16301 0.2302 0.0090 3.923 04 04101 0.1720 0.0067 3.913 04 04301 0.2048 0.0079 3.845 05 05101 0.2110 0.0080 3.782 07 07101 0.1851 0.0069 3.718 13 13401 0.2428 0.0090 3.688 06 06101 0.1921 0.0071 3.679 07 07401 0.2026 0.0074 3.666 07 07406 0.2076 0.0076 3.642 10 10101 0.2175 0.0074 3.393 01 01101 0.1862 0.0062 3.314 04 04102 0.1973 0.0065 3.272 14 14101 0.2004 0.0064 3.202 09 09101 0.2148 0.0066 3.075 16 16101 0.2131 0.0065 3.042 03 03101 0.1832 0.0052 2.846 11 11101 0.1825 0.0048 2.620 02 02101 0.1934 0.0047 2.426 12 12101 0.1449 0.0029 1.973 15 15101 0.2151 0.0007 0.331 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
